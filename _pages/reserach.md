---
layout: archive
title: "Research Highlights"
permalink: /research/
author_profile: true
---


<style>
firstauthor { color: gray; font-weight: bold; font-size: 0.8em}
author { color: gray; font-size: 0.8em}
venue { color: gray; font-size: 0.8em}
</style>


------


> **Accelerating DETR Convergence via Semantic-Aligned Matching**
>
> <img src="/images/SAM-DETR.jpg" alt="SAM-DETR" width="600"/>
>
> **TL;DR**&emsp; This paper presents SAM-DETR -- an efficient DETR-like object detector, which can converge within 12 epochs and outperform the strong Faster R-CNN (w/ FPN) baselines.
>
> <firstauthor>Gongjie Zhang</firstauthor><author>, Zhipeng Luo, Yingchen Yu, Kaiwen Cui, and Shijian Lu</author><venue><br>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR), 2022</venue>

---

> **Meta-DETR: Image-Level Few-Shot Object Detection with Inter-Class Correlation Exploitation**
>
> <img src="/images/MetaDETR1.jpg" alt="MetaDETR1" width="600"/>
>
> <img src="/images/MetaDETR2.jpg" alt="MetaDETR2" width="600"/>
>
> **TL;DR**&emsp; Meta-DETR entirely bypasses the proposal quality gap between base and novel classes, thus achieving better performance than R-CNN-based detectors. In addition, Meta-DETR meta-learns on a set of support classes, thus effectively leveraging the inter-class correlation for better transferability.
>
> <firstauthor>Gongjie Zhang</firstauthor><author>, Zhipeng Luo, Kaiwen Cui, and Shijian Lu</author><venue><br>Tech Report, ArXiv preprint: 2103.11731v3</venue>

---

> **Defect-GAN: High-Fidelity Defect Synthesis for Automated Defect Inspection**
>
> <img src="/images/DefectGAN.jpg" alt="Defect-GAN" width="600"/>
>
> <img src="/images/DefectGAN2.jpg" alt="Defect-GAN2" width="600"/>
>
> **TL;DR**&emsp; Defect samples are usually rare and expensive to label. This paper presents Defect-GAN to perform high-fidelity defect synthesis with many normal samples and a limited number of defect samples. We show that synthesized defect samples can be effectively leveraged to boost inspection accuracy. The technique is patent-protected and is being used in real scenarios.
>  
> <firstauthor>Gongjie Zhang</firstauthor><author>, Kaiwen Cui, Tzu-Yi Hung, and Shijian Lu</author><venue><br>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2021</venue>

---

> **Cascade EF-GAN: Progressive Facial Expression Editing with Local Focuses**
>
> <img src="/images/CascadeEFGAN.jpg" alt="CascadeEF-GAN" width="600"/>
>
> **TL;DR**&emsp; We achieve realistic and vivid facial expression editing by designing separate branches focusing on certain areas (e.g., eyes, noses), and perform the expression transformation in a cascaded manner.
>  
> <author>Rongliang Wu, </author><firstauthor>Gongjie Zhang</firstauthor><author>, Shijian Lu, and Tao Chen</author><venue><br>IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) (Oral), 2020</venue>

---

> **CAD-Net: A Context-Aware Detection Network for Objects in Remote Sensing Imagery**
>
> <img src="/images/CAD-Net.jpg" alt="CAD-Net" width="600"/>
>
> **TL;DR**&emsp; One of the earliest works to apply Faster R-CNN to rotated object detection in remote sensing images. The proposed CAD-Net effectively uses multi-level contextual information for robust object detection for satellite imagery.
>  
> <firstauthor>Gongjie Zhang</firstauthor><author>, Shijian Lu, and Wei Zhang</author><venue><br>IEEE Transactions on Geoscience and Remote Sensing (T-GRS), vol.57, no.12, 2019</venue>


---